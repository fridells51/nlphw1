{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242105c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gusfridell/battle/b-vae/test-train/torch-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/gusfridell/battle/b-vae/test-train/torch-env/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/gusfridell/battle/b-vae/test-train/torch-env/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <ABE0EE74-6D97-3B8C-B690-C44754774FBC> /Users/gusfridell/battle/b-vae/test-train/torch-env/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <CDAC6E34-8608-3E70-8B2F-32BCD38E90FB> /Users/gusfridell/battle/b-vae/test-train/torch-env/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/gusfridell/battle/b-vae/test-train/torch-env/lib/python3.8/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/gusfridell/battle/b-vae/test-train/torch-env/lib/python3.8/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import random\n",
    "\n",
    "mod = \"distilbert/distilgpt2\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(mod)\n",
    "model = AutoModelForCausalLM.from_pretrained(mod)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(109.6611)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose your paragraph\n",
    "paragraph = \"The trousers were sent to you (1) as a means of testing your initiative (A clever, wide-awake business concern should be able to make three-quarter length trousers a by-word of masculine fashion. Your advertising and merchandising programs are obviously faulty.) and (2) as a means of testing your ability to meet the standards requisite in a distributor of our quality product. (Our loyal and dependable outlets can vend any trouser bearing the Levy label no matter how abominable their design and construction. You are apparently a faithless people.) We do not wish to be bothered in the future by such tedious complaints. Please confine your correspondence to orders only. We are a busy and dynamic organization whose mission needless effrontery and harassment can only hinder. If you molest us again, sir, you may feel the sting of the lash across your pitiful shoulders.\"\n",
    "inputs = tokenizer(paragraph, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs.input_ids, labels=inputs.input_ids)\n",
    "    log_likelihood = outputs.loss * inputs.input_ids.shape[1]\n",
    "    perplexity = torch.exp(log_likelihood / inputs.input_ids.shape[1])\n",
    "\n",
    "words = paragraph.split()\n",
    "random.shuffle(words)\n",
    "shuffled_paragraph = \" \".join(words)\n",
    "\n",
    "shuffled_inputs = tokenizer(shuffled_paragraph, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    shuffled_outputs = model(shuffled_inputs.input_ids, labels=shuffled_inputs.input_ids)\n",
    "    shuffled_log_likelihood = shuffled_outputs.loss * shuffled_inputs.input_ids.shape[1]\n",
    "    shuffled_perplexity = torch.exp(shuffled_log_likelihood / shuffled_inputs.input_ids.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5d6d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1779.8390)\n",
      "tensor(109.6611)\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_perplexity)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98949deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time of war, the United States was the only country in the world to have a military presence. The United States was the only country in the world to have a military presence. The United States was the only country in the world to have a military presence\n",
      "temp 0.3\n",
      "Once upon a time when the world was in a state of flux, the world was in a state of flux. The world was in a state of flux. The world was in a state of flux. The world was in a state of flux. The world was in\n",
      "temp 0.6\n",
      "Once upon a time when the people of the world are getting in the way of making a living, I think we all need to be prepared for the inevitable.\n",
      "\n",
      "\n",
      "I think our current climate is very different than that of the past.\n",
      "The United States has\n",
      "temp 0.9\n",
      "Once upon a time of war and violence, it would be an honour to have the opportunity to do so. The French will always have the right to use the opportunity, and if it is not offered, the decision made over the course of the war might also change the\n",
      "temp 1.2\n",
      "Once upon a time when we had done so, at best I could have thrown all of his cards in one hand. If that happens, I'd have lost them for a good half an hour, since we did nothing wrong, but I hadn't gotten close to that\n",
      "temp 1.5\n",
      "Once upon a time, so will you get to enjoy The Mummy? Well first look at our infographic, the new season of the series!\n",
      "\n",
      "\n",
      "The Mummy by David Hare is part of this interactive collection: You can download it on a desktop browser:\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once upon a time\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "max_length = len(input_ids[0]) + 50\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "    input_ids = input_ids.to('cuda')\n",
    "greedy_output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=max_length,\n",
    "    do_sample=False,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(greedy_output[0]))\n",
    "\n",
    "temperatures = [0.3, 0.6, 0.9, 1.2, 1.5]\n",
    "for T in temperatures:\n",
    "    print(f\"temp {T}\")\n",
    "    sample_output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        temperature=T,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    print(tokenizer.decode(sample_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee2e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
